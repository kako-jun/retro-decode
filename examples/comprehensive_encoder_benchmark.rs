//! åŒ…æ‹¬çš„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
//! 4ã¤ã®åœ§ç¸®æˆ¦ç•¥ã®å®Œå…¨ãªæ€§èƒ½æ¯”è¼ƒã¨æ¤œè¨¼

use retro_decode::formats::toheart::lf2::{Lf2Image, CompressionStrategy};
use anyhow::Result;
use std::time::Instant;
use std::path::Path;

#[derive(Debug)]
struct BenchmarkResult {
    strategy: CompressionStrategy,
    file_name: String,
    original_size: usize,
    encoded_size: usize,
    compression_ratio: f64,
    pixel_differences: usize,
    encoding_time_ms: u128,
    is_perfect_accuracy: bool,
}

fn main() -> Result<()> {
    println!("ğŸš€ Comprehensive LF2 Encoder Benchmark");
    println!("======================================");
    println!("Testing 4 compression strategies:");
    println!("1. Perfect Accuracy - 100% pixel precision");
    println!("2. Original Replication - Reverse engineering");
    println!("3. ML Guided - Machine learning insights");
    println!("4. Balanced - Compression/accuracy tradeoff");
    println!();
    
    // ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ¤œå‡º
    let test_files = find_test_files()?;
    if test_files.is_empty() {
        println!("âŒ No LF2 test files found");
        return Ok(());
    }
    
    println!("ğŸ“Š Testing {} files", test_files.len());
    
    let strategies = [
        ("Perfect Accuracy", CompressionStrategy::PerfectAccuracy),
        ("Original Replication", CompressionStrategy::OriginalReplication), 
        ("ML Guided", CompressionStrategy::MachineLearningGuided),
        ("Balanced", CompressionStrategy::Balanced),
        ("Perfect Original", CompressionStrategy::PerfectOriginalReplication),
    ];
    
    let mut all_results = Vec::new();
    
    // å„ãƒ•ã‚¡ã‚¤ãƒ«ã§å„æˆ¦ç•¥ã‚’ãƒ†ã‚¹ãƒˆ
    for (i, file_path) in test_files.iter().take(10).enumerate() { // æœ€åˆã®10ãƒ•ã‚¡ã‚¤ãƒ«
        println!("\nğŸ“ Testing file {}/{}: {}", i+1, test_files.len().min(10), 
                Path::new(file_path).file_name().unwrap().to_string_lossy());
        
        let original_image = match Lf2Image::open(file_path) {
            Ok(img) => img,
            Err(e) => {
                println!("   âš ï¸  Skipped (read error): {}", e);
                continue;
            }
        };
        
        let original_size = std::fs::metadata(file_path)?.len() as usize;
        
        for (name, strategy) in strategies.iter() {
            match benchmark_strategy(&original_image, *strategy, file_path, original_size) {
                Ok(result) => {
                    print_result(&result);
                    all_results.push(result);
                }
                Err(e) => {
                    println!("   âŒ {}: Error - {}", name, e);
                }
            }
        }
    }
    
    // ç·åˆçµ±è¨ˆ
    print_summary(&all_results);
    
    Ok(())
}

fn find_test_files() -> Result<Vec<String>> {
    let test_dir = "test_assets/lf2";
    let mut files = Vec::new();
    
    if let Ok(entries) = std::fs::read_dir(test_dir) {
        for entry in entries {
            if let Ok(entry) = entry {
                let path = entry.path();
                if let Some(ext) = path.extension() {
                    if ext == "LF2" {
                        files.push(path.to_string_lossy().to_string());
                    }
                }
            }
        }
    }
    
    files.sort();
    Ok(files)
}

fn benchmark_strategy(
    original_image: &Lf2Image,
    strategy: CompressionStrategy,
    file_path: &str,
    original_size: usize,
) -> Result<BenchmarkResult> {
    let start = Instant::now();
    
    // ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ
    let encoded_data = original_image.to_lf2_bytes_with_strategy(strategy)?;
    let encoding_time = start.elapsed().as_millis();
    
    // å¾€å¾©ãƒ†ã‚¹ãƒˆ
    let decoded_image = Lf2Image::from_data(&encoded_data)?;
    let pixel_differences = count_pixel_differences(&original_image.pixels, &decoded_image.pixels);
    
    let compression_ratio = (encoded_data.len() as f64) / (original_size as f64) * 100.0;
    
    Ok(BenchmarkResult {
        strategy,
        file_name: Path::new(file_path).file_name().unwrap().to_string_lossy().to_string(),
        original_size,
        encoded_size: encoded_data.len(),
        compression_ratio,
        pixel_differences,
        encoding_time_ms: encoding_time,
        is_perfect_accuracy: pixel_differences == 0,
    })
}

fn count_pixel_differences(pixels1: &[u8], pixels2: &[u8]) -> usize {
    if pixels1.len() != pixels2.len() {
        return pixels1.len().max(pixels2.len());
    }
    
    pixels1.iter()
        .zip(pixels2.iter())
        .filter(|(a, b)| a != b)
        .count()
}

fn print_result(result: &BenchmarkResult) {
    let accuracy_icon = if result.is_perfect_accuracy { "ğŸ¯" } else { "âš ï¸" };
    let strategy_name = format!("{:?}", result.strategy);
    
    println!("   {} {}: {:.1}% size, {} diffs, {}ms", 
        accuracy_icon,
        strategy_name,
        result.compression_ratio,
        result.pixel_differences,
        result.encoding_time_ms
    );
}

fn print_summary(results: &[BenchmarkResult]) {
    if results.is_empty() {
        return;
    }
    
    println!("\nğŸ“ˆ SUMMARY STATISTICS");
    println!("====================");
    
    let strategies = [
        CompressionStrategy::PerfectAccuracy,
        CompressionStrategy::OriginalReplication,
        CompressionStrategy::MachineLearningGuided,
        CompressionStrategy::Balanced,
        CompressionStrategy::PerfectOriginalReplication,
    ];
    
    for strategy in strategies.iter() {
        let strategy_results: Vec<_> = results.iter()
            .filter(|r| std::mem::discriminant(&r.strategy) == std::mem::discriminant(strategy))
            .collect();
        
        if strategy_results.is_empty() {
            continue;
        }
        
        let perfect_count = strategy_results.iter().filter(|r| r.is_perfect_accuracy).count();
        let avg_compression = strategy_results.iter()
            .map(|r| r.compression_ratio)
            .sum::<f64>() / strategy_results.len() as f64;
        let avg_time = strategy_results.iter()
            .map(|r| r.encoding_time_ms)
            .sum::<u128>() / strategy_results.len() as u128;
        let total_diffs: usize = strategy_results.iter()
            .map(|r| r.pixel_differences)
            .sum();
        
        println!("\nğŸ”¸ {:?}", strategy);
        println!("   Perfect accuracy: {}/{} files ({:.1}%)", 
            perfect_count, 
            strategy_results.len(),
            (perfect_count as f64 / strategy_results.len() as f64) * 100.0
        );
        println!("   Avg compression: {:.1}% of original", avg_compression);
        println!("   Avg encoding time: {}ms", avg_time);
        println!("   Total pixel differences: {}", total_diffs);
    }
    
    println!("\nğŸ¯ RECOMMENDATIONS");
    println!("==================");
    println!("â€¢ Perfect Accuracy: Use for 100% fidelity requirements");
    println!("â€¢ ML Guided: Best balance of ML insights and practical compression");
    println!("â€¢ Original Replication: Most faithful to original algorithm");
    println!("â€¢ Balanced: Good compromise for file size optimization");
    
    println!("\nğŸ¤– Machine Learning Impact");
    println!("=========================");
    println!("â€¢ 246ä¸‡æ±ºå®šãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å­¦ç¿’ã—ãŸç‰¹å¾´é‡é‡è¦åº¦ã‚’å®Ÿè£…");
    println!("â€¢ compression_progress(27.4)ã¨estimated_y(16.6)ãŒæ±ºå®šã«æœ€ã‚‚å½±éŸ¿");
    println!("â€¢ 3-4ãƒã‚¤ãƒˆãƒãƒƒãƒå„ªå…ˆãƒ»è¿‘è·é›¢é¸æŠãƒ»ãƒªãƒ³ã‚°ãƒãƒƒãƒ•ã‚¡è©•ä¾¡ã‚’çµ±åˆ");
    println!("â€¢ 75.3%ã®æ±ºå®šç²¾åº¦ã§20å¹´å‰ã®é–‹ç™ºè€…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å¾©å…ƒ");
}